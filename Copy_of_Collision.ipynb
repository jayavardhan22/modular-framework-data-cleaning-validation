{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "FILE_NAME = \"/content/sample_data/Motor_Vehicle_Collisions_-_Crashes.csv\"\n",
        "GEOSPATIAL_COLS = ['LATITUDE', 'LONGITUDE']\n",
        "INJURY_COLS = [\n",
        "    'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
        "    'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
        "    'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
        "    'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED'\n",
        "]\n",
        "\n",
        "# --- DATA LOADING and INITIAL CLEANING ---\n",
        "try:\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(FILE_NAME, low_memory=False)\n",
        "    print(f\"Successfully loaded '{FILE_NAME}'. Rows: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{FILE_NAME}' was not found. Check the file path.\")\n",
        "    df = None # Set to None to skip subsequent blocks if loading fails\n",
        "\n",
        "if df is not None:\n",
        "    # 1. Type Conversion and Standardization for Analysis\n",
        "    df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'], format='%m/%d/%Y', errors='coerce')\n",
        "    df['CRASH TIME'] = df['CRASH TIME'].astype(str).str.strip().str.slice(0, 5)\n",
        "\n",
        "    # Combine date and time for time-series analysis\n",
        "    df['CRASH DATETIME'] = pd.to_datetime(\n",
        "        df['CRASH DATE'].dt.strftime('%Y-%m-%d') + ' ' + df['CRASH TIME'],\n",
        "        errors='coerce'\n",
        "    )\n",
        "    # The framework modules need a clean, non-indexed DF, so we create a copy:\n",
        "    raw_df = df.copy().reset_index(drop=True)\n",
        "\n",
        "    # Coerce injury/kill counts to numeric (crucial for rule validation)\n",
        "    for col in INJURY_COLS:\n",
        "        raw_df[col] = pd.to_numeric(raw_df[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    print(\"\\nInitial data types (first 10 columns):\")\n",
        "    print(raw_df.dtypes.head(10))\n",
        "\n",
        "    # Display the first few rows of the clean, non-indexed data for the framework\n",
        "    print(\"\\n### Cleaned DataFrame Head for Modular Processing ###\")\n",
        "    display(raw_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "KcJ3I6nuQj3V",
        "outputId": "064d627d-3db6-47ac-9096-7c941bbdad18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded '/content/sample_data/Motor_Vehicle_Collisions_-_Crashes.csv'. Rows: 464934\n",
            "\n",
            "Initial data types (first 10 columns):\n",
            "CRASH DATE           datetime64[ns]\n",
            "CRASH TIME                   object\n",
            "BOROUGH                      object\n",
            "ZIP CODE                    float64\n",
            "LATITUDE                    float64\n",
            "LONGITUDE                   float64\n",
            "LOCATION                     object\n",
            "ON STREET NAME               object\n",
            "CROSS STREET NAME            object\n",
            "OFF STREET NAME              object\n",
            "dtype: object\n",
            "\n",
            "### Cleaned DataFrame Head for Modular Processing ###\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  CRASH DATE CRASH TIME   BOROUGH  ZIP CODE  LATITUDE  LONGITUDE  \\\n",
              "0 2021-09-11       2:39       NaN       NaN       NaN        NaN   \n",
              "1 2022-03-26      11:45       NaN       NaN       NaN        NaN   \n",
              "2 2023-11-01       1:29  BROOKLYN   11230.0  40.62179 -73.970024   \n",
              "3 2022-06-29       6:55       NaN       NaN       NaN        NaN   \n",
              "4 2022-09-21      13:21       NaN       NaN       NaN        NaN   \n",
              "\n",
              "                 LOCATION           ON STREET NAME CROSS STREET NAME  \\\n",
              "0                     NaN    WHITESTONE EXPRESSWAY         20 AVENUE   \n",
              "1                     NaN  QUEENSBORO BRIDGE UPPER               NaN   \n",
              "2  (40.62179, -73.970024)            OCEAN PARKWAY          AVENUE K   \n",
              "3                     NaN       THROGS NECK BRIDGE               NaN   \n",
              "4                     NaN          BROOKLYN BRIDGE               NaN   \n",
              "\n",
              "  OFF STREET NAME  ...  CONTRIBUTING FACTOR VEHICLE 3  \\\n",
              "0             NaN  ...                            NaN   \n",
              "1             NaN  ...                            NaN   \n",
              "2             NaN  ...                    Unspecified   \n",
              "3             NaN  ...                            NaN   \n",
              "4             NaN  ...                            NaN   \n",
              "\n",
              "   CONTRIBUTING FACTOR VEHICLE 4  CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n",
              "0                            NaN                            NaN       4455765   \n",
              "1                            NaN                            NaN       4513547   \n",
              "2                            NaN                            NaN       4675373   \n",
              "3                            NaN                            NaN       4541903   \n",
              "4                            NaN                            NaN       4566131   \n",
              "\n",
              "                   VEHICLE TYPE CODE 1  VEHICLE TYPE CODE 2  \\\n",
              "0                                Sedan                Sedan   \n",
              "1                                Sedan                  NaN   \n",
              "2                                Moped                Sedan   \n",
              "3                                Sedan        Pick-up Truck   \n",
              "4  Station Wagon/Sport Utility Vehicle                  NaN   \n",
              "\n",
              "   VEHICLE TYPE CODE 3  VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \\\n",
              "0                  NaN                  NaN                 NaN   \n",
              "1                  NaN                  NaN                 NaN   \n",
              "2                Sedan                  NaN                 NaN   \n",
              "3                  NaN                  NaN                 NaN   \n",
              "4                  NaN                  NaN                 NaN   \n",
              "\n",
              "       CRASH DATETIME  \n",
              "0 2021-09-11 02:39:00  \n",
              "1 2022-03-26 11:45:00  \n",
              "2 2023-11-01 01:29:00  \n",
              "3 2022-06-29 06:55:00  \n",
              "4 2022-09-21 13:21:00  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adf7d481-1121-4e08-908c-c4bf43f96d73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRASH DATE</th>\n",
              "      <th>CRASH TIME</th>\n",
              "      <th>BOROUGH</th>\n",
              "      <th>ZIP CODE</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>ON STREET NAME</th>\n",
              "      <th>CROSS STREET NAME</th>\n",
              "      <th>OFF STREET NAME</th>\n",
              "      <th>...</th>\n",
              "      <th>CONTRIBUTING FACTOR VEHICLE 3</th>\n",
              "      <th>CONTRIBUTING FACTOR VEHICLE 4</th>\n",
              "      <th>CONTRIBUTING FACTOR VEHICLE 5</th>\n",
              "      <th>COLLISION_ID</th>\n",
              "      <th>VEHICLE TYPE CODE 1</th>\n",
              "      <th>VEHICLE TYPE CODE 2</th>\n",
              "      <th>VEHICLE TYPE CODE 3</th>\n",
              "      <th>VEHICLE TYPE CODE 4</th>\n",
              "      <th>VEHICLE TYPE CODE 5</th>\n",
              "      <th>CRASH DATETIME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-11</td>\n",
              "      <td>2:39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WHITESTONE EXPRESSWAY</td>\n",
              "      <td>20 AVENUE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4455765</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2021-09-11 02:39:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-03-26</td>\n",
              "      <td>11:45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>QUEENSBORO BRIDGE UPPER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4513547</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-03-26 11:45:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-11-01</td>\n",
              "      <td>1:29</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>11230.0</td>\n",
              "      <td>40.62179</td>\n",
              "      <td>-73.970024</td>\n",
              "      <td>(40.62179, -73.970024)</td>\n",
              "      <td>OCEAN PARKWAY</td>\n",
              "      <td>AVENUE K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Unspecified</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4675373</td>\n",
              "      <td>Moped</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-11-01 01:29:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-06-29</td>\n",
              "      <td>6:55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>THROGS NECK BRIDGE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4541903</td>\n",
              "      <td>Sedan</td>\n",
              "      <td>Pick-up Truck</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-06-29 06:55:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-21</td>\n",
              "      <td>13:21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BROOKLYN BRIDGE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4566131</td>\n",
              "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-21 13:21:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adf7d481-1121-4e08-908c-c4bf43f96d73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adf7d481-1121-4e08-908c-c4bf43f96d73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adf7d481-1121-4e08-908c-c4bf43f96d73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-560b199f-4af3-485e-a71f-51137e6d6612\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-560b199f-4af3-485e-a71f-51137e6d6612')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-560b199f-4af3-485e-a71f-51137e6d6612 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def schema_and_rule_validation(df: pd.DataFrame):\n",
        "    \"\"\"Applies structural and logical checks using pure Pandas and returns a validation report.\"\"\"\n",
        "\n",
        "    # Global constants defined in Block 1 are used here: INJURY_COLS, GEOSPATIAL_COLS\n",
        "\n",
        "    print(\"\\n--- Running Module 1: Schema and Rule Checks (Pure Pandas) ---\")\n",
        "    validation_report = {}\n",
        "\n",
        "    # A. SCHEMA ENFORCEMENT\n",
        "    expected_core_cols = ['COLLISION_ID', 'CRASH DATE', 'CRASH TIME'] + INJURY_COLS\n",
        "    missing_cols = [col for col in expected_core_cols if col not in df.columns]\n",
        "    validation_report['Missing_Columns'] = missing_cols\n",
        "\n",
        "    # B. RULE-BASED LOGIC ðŸš¦\n",
        "\n",
        "    # Rule 1: Non-Negative Injury Counts (Fundamental logic check)\n",
        "    # Finds and corrects records where injury/kill counts are illogical (< 0)\n",
        "    for col in INJURY_COLS:\n",
        "        negative_count = (df[col] < 0).sum()\n",
        "        if negative_count > 0:\n",
        "            # Clean the data by setting negative values to 0 (Correction)\n",
        "            df.loc[df[col] < 0, col] = 0\n",
        "            validation_report[f\"Rule_Violation_Negative_{col}\"] = f\"{negative_count} negative values found and corrected to 0.\"\n",
        "\n",
        "    # Rule 2: Geospatial Boundary Check (Range Validation)\n",
        "    # Flag data significantly outside approximate NYC bounds: LAT (40.4 to 41.0), LONG (-74.3 to -73.7)\n",
        "    lat_violations = df[\n",
        "        (df['LATITUDE'] < 40.4) | (df['LATITUDE'] > 41.0)\n",
        "    ].dropna(subset=['LATITUDE']).shape[0]\n",
        "\n",
        "    lon_violations = df[\n",
        "        (df['LONGITUDE'] < -74.3) | (df['LONGITUDE'] > -73.7)\n",
        "    ].dropna(subset=['LONGITUDE']).shape[0]\n",
        "\n",
        "    # Total violations (we assume a violation in one is a problem for the record)\n",
        "    if lat_violations + lon_violations > 0:\n",
        "        validation_report[\"Rule_Violation_Geospatial\"] = f\"{lat_violations} LAT or {lon_violations} LON values outside NYC bounds.\"\n",
        "\n",
        "    # --- Validation Summary and Explainability ---\n",
        "    print(\"\\nValidation Report (Issues Identified and Explained):\")\n",
        "    if any(validation_report.values()):\n",
        "        for key, value in validation_report.items():\n",
        "            if value and (isinstance(value, int) and value > 0 or (isinstance(value, list) and value) or (isinstance(value, str) and not value.startswith('0'))):\n",
        "                 print(f\"- **{key}:** {value}\")\n",
        "    else:\n",
        "        print(\"- **No Major Rule Violations or Schema Issues Detected.**\")\n",
        "\n",
        "    return df, validation_report # Return cleaned df and the report\n",
        "\n",
        "# Execute Module 1\n",
        "# This executes the function using the DataFrame prepared in Block 1\n",
        "if 'raw_df' in locals() and raw_df is not None:\n",
        "    # Pass a copy to the function to maintain the raw state outside the module\n",
        "    rule_validated_df, validation_summary = schema_and_rule_validation(raw_df.copy())"
      ],
      "metadata": {
        "id": "E7yJTC_3Q8An",
        "outputId": "25a752d1-8c84-4c12-bbd3-8a0e7816c457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Module 1: Schema and Rule Checks (Pure Pandas) ---\n",
            "\n",
            "Validation Report (Issues Identified and Explained):\n",
            "- **Rule_Violation_Geospatial:** 3325 LAT or 3325 LON values outside NYC bounds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def anomaly_detection(df: pd.DataFrame):\n",
        "    \"\"\"Applies Isolation Forest to detect unusual patterns based on key numerical features.\"\"\"\n",
        "\n",
        "    # Global constants defined in Block 1 are used here: INJURY_COLS, GEOSPATIAL_COLS\n",
        "\n",
        "    print(\"\\n--- Running Module 2: Anomaly Detection Checks (Isolation Forest) ---\")\n",
        "\n",
        "    # 1. Feature Engineering: Create a summary feature for the model\n",
        "    df['TOTAL_CASUALTIES'] = df[INJURY_COLS].sum(axis=1)\n",
        "\n",
        "    # 2. Select features for the model\n",
        "    model_features = GEOSPATIAL_COLS + ['TOTAL_CASUALTIES']\n",
        "    anomaly_data = df[model_features].copy()\n",
        "\n",
        "    # 3. Handle NaNs for the model run (Imputation)\n",
        "    # Replace NaNs with an imputed value (e.g., central NYC for location)\n",
        "    anomaly_data['LATITUDE'].fillna(40.73, inplace=True)\n",
        "    anomaly_data['LONGITUDE'].fillna(-73.93, inplace=True)\n",
        "\n",
        "    # 4. Apply Isolation Forest\n",
        "    # contamination='auto' lets the algorithm estimate the fraction of outliers\n",
        "    iso_forest = IsolationForest(contamination='auto', random_state=42)\n",
        "\n",
        "    # -1 means anomaly (outlier), 1 means normal (inlier)\n",
        "    df['ANOMALY_FLAG'] = iso_forest.fit_predict(anomaly_data)\n",
        "\n",
        "    anomalies = df[df['ANOMALY_FLAG'] == -1]\n",
        "\n",
        "    print(f\"Detected {len(anomalies):,} potential anomalies using Isolation Forest.\")\n",
        "\n",
        "    # Explainability: Print the top 5 anomalies for review\n",
        "    print(\"\\nTop 5 Records Flagged as Anomalies (Requires Human Review):\")\n",
        "    print(anomalies[['COLLISION_ID', 'CRASH DATE', 'LATITUDE', 'LONGITUDE', 'TOTAL_CASUALTIES']].head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Execute Module 2\n",
        "# This uses the 'rule_validated_df' which now has clean/corrected injury counts\n",
        "if 'rule_validated_df' in locals() and rule_validated_df is not None:\n",
        "    anomaly_flagged_df = anomaly_detection(rule_validated_df.copy())"
      ],
      "metadata": {
        "id": "B_YkzvpeQ_n_",
        "outputId": "01471cdc-a23b-457f-a7a3-c552a31a4d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Module 2: Anomaly Detection Checks (Isolation Forest) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1600270818.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anomaly_data['LATITUDE'].fillna(40.73, inplace=True)\n",
            "/tmp/ipython-input-1600270818.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anomaly_data['LONGITUDE'].fillna(-73.93, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 28,739 potential anomalies using Isolation Forest.\n",
            "\n",
            "Top 5 Records Flagged as Anomalies (Requires Human Review):\n",
            "    COLLISION_ID CRASH DATE  LATITUDE  LONGITUDE  TOTAL_CASUALTIES\n",
            "13       4486660 2021-12-14  40.86816  -73.83148                 4\n",
            "20       4486635 2021-12-14  40.66684  -73.78941                 4\n",
            "22       4486991 2021-12-14  40.65068  -73.95881                 8\n",
            "23       4486284 2021-12-14       NaN        NaN                 6\n",
            "30       4487001 2021-12-13  40.63165  -74.08762                 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_results(flagged_df: pd.DataFrame, report: dict):\n",
        "    \"\"\"Provides a consolidated summary of the framework's output.\"\"\"\n",
        "\n",
        "    print(\"\\n=======================================================\")\n",
        "    print(\"Modular Framework Output Summary for NYC Crash Data\")\n",
        "    print(\"=======================================================\")\n",
        "\n",
        "    # 1. Summary of Rule/Schema Violations (from Module 1 - Transparency)\n",
        "    print(\"## 1. Rule-Based/Schema Validation (Transparency & Explainability)\")\n",
        "    violation_keys = [k for k, v in report.items() if v and (isinstance(v, int) and v > 0 or isinstance(v, str) and not v.startswith('0'))]\n",
        "    print(f\"Total Types of Rule/Schema Violations Found: **{len(violation_keys)}**\")\n",
        "    print(f\"Example Violations: {', '.join(violation_keys[:3]) if violation_keys else 'None'}\")\n",
        "    print(\"> The initial data cleaning step corrected fundamental issues like negative injury counts.\")\n",
        "\n",
        "    # 2. Summary of Anomalies (from Module 2 - Accuracy/Speed)\n",
        "    anomaly_count = (flagged_df['ANOMALY_FLAG'] == -1).sum()\n",
        "    print(\"\\n## 2. Unsupervised Anomaly Detection (Accuracy/Speed)\")\n",
        "    print(f\"Total Records Processed: {len(flagged_df)}\")\n",
        "    print(f\"Total Records Flagged as Outliers (Anomaly Flag = -1): **{anomaly_count:,}**\")\n",
        "\n",
        "    # 3. Next Steps (Actionable Output)\n",
        "    print(\"\\n## 3. Actionable Output for Data Quality Improvement\")\n",
        "    if anomaly_count > 0 or len(violation_keys) > 0:\n",
        "        print(f\"The framework has generated a consolidated view of data quality issues across **{len(flagged_df)}** records.\")\n",
        "        print(f\"The **{anomaly_count:,}** outlier records (based on location/injury severity) require priority review.\")\n",
        "    else:\n",
        "        print(\"Data quality appears high based on the current rules and anomaly models.\")\n",
        "\n",
        "# Execute Final Summary\n",
        "if raw_df is not None:\n",
        "    summarize_results(anomaly_flagged_df, validation_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6-YdWYJRCw_",
        "outputId": "c9782f2e-d71d-41b8-b222-2b54a6ef8bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================================\n",
            "Modular Framework Output Summary for NYC Crash Data\n",
            "=======================================================\n",
            "## 1. Rule-Based/Schema Validation (Transparency & Explainability)\n",
            "Total Types of Rule/Schema Violations Found: **1**\n",
            "Example Violations: Rule_Violation_Geospatial\n",
            "> The initial data cleaning step corrected fundamental issues like negative injury counts.\n",
            "\n",
            "## 2. Unsupervised Anomaly Detection (Accuracy/Speed)\n",
            "Total Records Processed: 205659\n",
            "Total Records Flagged as Outliers (Anomaly Flag = -1): **28,739**\n",
            "\n",
            "## 3. Actionable Output for Data Quality Improvement\n",
            "The framework has generated a consolidated view of data quality issues across **205659** records.\n",
            "The **28,739** outlier records (based on location/injury severity) require priority review.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_results(flagged_df: pd.DataFrame, report: dict):\n",
        "    \"\"\"Provides a consolidated summary of the framework's output.\"\"\"\n",
        "\n",
        "    print(\"\\n=======================================================\")\n",
        "    print(\"Modular Framework Output Summary for NYC Crash Data\")\n",
        "    print(\"=======================================================\")\n",
        "\n",
        "    # 1. Summary of Rule/Schema Violations (from Module 1 - Transparency)\n",
        "    print(\"## 1. Rule-Based/Schema Validation (Transparency & Explainability)\")\n",
        "    violation_keys = [k for k, v in report.items() if v and (isinstance(v, int) and v > 0 or isinstance(v, str) and not v.startswith('0'))]\n",
        "    print(f\"Total Types of Rule/Schema Violations Found: **{len(violation_keys)}**\")\n",
        "    print(f\"Example Violations: {', '.join(violation_keys[:3]) if violation_keys else 'None'}\")\n",
        "    print(\"> This module successfully corrected fundamental errors (like negative counts) and flagged range violations.\")\n",
        "\n",
        "    # 2. Summary of Anomalies (from Module 2 - Accuracy/Speed)\n",
        "    anomaly_count = (flagged_df['ANOMALY_FLAG'] == -1).sum()\n",
        "    print(\"\\n## 2. Unsupervised Anomaly Detection (Accuracy/Speed)\")\n",
        "    print(f\"Total Records Processed: {len(flagged_df):,}\")\n",
        "    print(f\"Total Records Flagged as Outliers (Anomaly Flag = -1): **{anomaly_count:,}**\")\n",
        "\n",
        "    # 3. Next Steps (Actionable Output)\n",
        "    print(\"\\n## 3. Actionable Output for Data Quality Improvement\")\n",
        "    if anomaly_count > 0 or len(violation_keys) > 0:\n",
        "        print(f\"The framework has generated a consolidated view of data quality issues across all {len(flagged_df):,} records.\")\n",
        "        print(f\"The **{anomaly_count:,}** outlier records require priority review for potential data entry errors or extreme, rare events.\")\n",
        "    else:\n",
        "        print(\"Data quality appears high based on the current rules and anomaly models.\")\n",
        "\n",
        "# Execute Final Summary\n",
        "if 'anomaly_flagged_df' in locals() and anomaly_flagged_df is not None:\n",
        "    summarize_results(anomaly_flagged_df, validation_summary)"
      ],
      "metadata": {
        "id": "JPVhX_DHRGwy",
        "outputId": "fdf391b8-8331-466a-8de3-d531f81e3fdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================================\n",
            "Modular Framework Output Summary for NYC Crash Data\n",
            "=======================================================\n",
            "## 1. Rule-Based/Schema Validation (Transparency & Explainability)\n",
            "Total Types of Rule/Schema Violations Found: **1**\n",
            "Example Violations: Rule_Violation_Geospatial\n",
            "> This module successfully corrected fundamental errors (like negative counts) and flagged range violations.\n",
            "\n",
            "## 2. Unsupervised Anomaly Detection (Accuracy/Speed)\n",
            "Total Records Processed: 205,659\n",
            "Total Records Flagged as Outliers (Anomaly Flag = -1): **28,739**\n",
            "\n",
            "## 3. Actionable Output for Data Quality Improvement\n",
            "The framework has generated a consolidated view of data quality issues across all 205,659 records.\n",
            "The **28,739** outlier records require priority review for potential data entry errors or extreme, rare events.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def schema_enforcement(df: pd.DataFrame, report: dict):\n",
        "    \"\"\"\n",
        "    Applies schema validation to ensure structural integrity (column types, required fields).\n",
        "    The framework is designed to check for core columns and data type consistency.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n--- Running Module 3: Schema Enforcement (Structure Check) ---\")\n",
        "\n",
        "    # Define the expected schema for core analytical columns\n",
        "    expected_schema = {\n",
        "        'COLLISION_ID': 'int64',\n",
        "        'CRASH DATETIME': 'datetime64[ns]',\n",
        "        'LATITUDE': 'float64',\n",
        "        'LONGITUDE': 'float64',\n",
        "        'TOTAL_CASUALTIES': 'int32', # Feature engineered in Module 2\n",
        "        'ANOMALY_FLAG': 'int32'      # Flag added in Module 2\n",
        "    }\n",
        "\n",
        "    # C. SCHEMA ENFORCEMENT\n",
        "\n",
        "    # Rule 3: Required Column Check\n",
        "    required_cols = list(expected_schema.keys())\n",
        "    missing_cols_after_modules = [col for col in required_cols if col not in df.columns]\n",
        "\n",
        "    if missing_cols_after_modules:\n",
        "        report[\"Schema_Violation_Missing_Core_Columns\"] = f\"Missing required columns: {missing_cols_after_modules}\"\n",
        "\n",
        "    # Rule 4: Data Type Consistency Check\n",
        "    type_violations = []\n",
        "    for col, expected_type in expected_schema.items():\n",
        "        if col in df.columns:\n",
        "            # Check if the actual type matches the expected type (ignoring NaN representation difference for float/int)\n",
        "            actual_type_group = df[col].dtype.name.split('[')[0] # Get base type (e.g., 'datetime64', 'float64')\n",
        "            expected_type_group = expected_type.split('[')[0]\n",
        "\n",
        "            if not actual_type_group.startswith(expected_type_group.replace('32', '').replace('64', '')):\n",
        "                type_violations.append(f\"{col} (Expected: {expected_type}, Actual: {df[col].dtype.name})\")\n",
        "\n",
        "    if type_violations:\n",
        "        report[\"Schema_Violation_Type_Mismatches\"] = type_violations\n",
        "        # Note: In a production system, you would apply corrections here, but for demonstration, we only flag.\n",
        "\n",
        "    print(\"Schema Validation Report (Issues Identified):\")\n",
        "    if type_violations or missing_cols_after_modules:\n",
        "        for key, value in report.items():\n",
        "            if key.startswith(\"Schema_Violation\"):\n",
        "                print(f\"- **{key}:** {value}\")\n",
        "    else:\n",
        "        print(\"- **No Schema Violations Detected.**\")\n",
        "\n",
        "    return df, report\n",
        "\n",
        "\n",
        "# --- EXECUTION OF MODULE 3 AND FINAL SUMMARY ---\n",
        "if 'anomaly_flagged_df' in locals() and anomaly_flagged_df is not None:\n",
        "    # Pass the DataFrame and the existing validation_summary (report) to Module 3\n",
        "    final_validated_df, final_validation_summary = schema_enforcement(anomaly_flagged_df.copy(), validation_summary)\n",
        "\n",
        "    # Re-execute the final summary function using the output of all modules\n",
        "    summarize_results(final_validated_df, final_validation_summary)"
      ],
      "metadata": {
        "id": "BAs-EMrhSH3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d6ba4c-4661-4ce0-dc96-fc59bc29825d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Module 3: Schema Enforcement (Structure Check) ---\n",
            "Schema Validation Report (Issues Identified):\n",
            "- **No Schema Violations Detected.**\n",
            "\n",
            "=======================================================\n",
            "Modular Framework Output Summary for NYC Crash Data\n",
            "=======================================================\n",
            "## 1. Rule-Based/Schema Validation (Transparency & Explainability)\n",
            "Total Types of Rule/Schema Violations Found: **1**\n",
            "Example Violations: Rule_Violation_Geospatial\n",
            "> This module successfully corrected fundamental errors (like negative counts) and flagged range violations.\n",
            "\n",
            "## 2. Unsupervised Anomaly Detection (Accuracy/Speed)\n",
            "Total Records Processed: 205,659\n",
            "Total Records Flagged as Outliers (Anomaly Flag = -1): **28,739**\n",
            "\n",
            "## 3. Actionable Output for Data Quality Improvement\n",
            "The framework has generated a consolidated view of data quality issues across all 205,659 records.\n",
            "The **28,739** outlier records require priority review for potential data entry errors or extreme, rare events.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# --- CONFIGURATION (Reused from previous steps) ---\n",
        "FILE_NAME = \"Motor_Vehicle_Collisions_Crashes.csv\" # Adjust path if necessary\n",
        "GEOSPATIAL_COLS = ['LATITUDE', 'LONGITUDE']\n",
        "INJURY_COLS = [\n",
        "    'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
        "    'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
        "    'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
        "    'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED'\n",
        "]\n",
        "\n",
        "# --- 1. DATA RELOAD AND INITIAL CLEANING ---\n",
        "try:\n",
        "    df = pd.read_csv(FILE_NAME, low_memory=False)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{FILE_NAME}' was not found. Cannot proceed with timing.\")\n",
        "    exit()\n",
        "\n",
        "# Coerce injury/kill counts to numeric (crucial for rule validation)\n",
        "for col in INJURY_COLS:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Combine date and time for time-series analysis (needed for schema check)\n",
        "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'], format='%m/%d/%Y', errors='coerce')\n",
        "df['CRASH TIME'] = df['CRASH TIME'].astype(str).str.strip().str.slice(0, 5)\n",
        "df['CRASH DATETIME'] = pd.to_datetime(\n",
        "    df['CRASH DATE'].dt.strftime('%Y-%m-%d') + ' ' + df['CRASH TIME'],\n",
        "    errors='coerce'\n",
        ")\n",
        "raw_df = df.copy().reset_index(drop=True)\n",
        "\n",
        "\n",
        "# --- 2. TIMED EXECUTION OF THE FULL FRAMEWORK ---\n",
        "start_time = time.time()\n",
        "validation_summary = {} # Initialize report\n",
        "\n",
        "# Module 1 Execution\n",
        "rule_validated_df, validation_summary = schema_and_rule_validation(raw_df.copy())\n",
        "print(f\"Module 1 completed.\")\n",
        "\n",
        "# Module 2 Execution\n",
        "anomaly_flagged_df = anomaly_detection(rule_validated_df.copy())\n",
        "print(f\"Module 2 completed.\")\n",
        "\n",
        "# Module 3 Execution\n",
        "final_validated_df, final_validation_summary = schema_enforcement(anomaly_flagged_df.copy(), validation_summary)\n",
        "print(f\"Module 3 completed.\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(\"\\n--- FINAL METRIC: SCALABILITY AND SPEED ---\")\n",
        "print(f\"Total Records Processed: {len(raw_df):,}\")\n",
        "print(f\"Total Framework Execution Time: **{total_time:.2f} seconds**\")\n",
        "print(f\"This metric demonstrates the framework's **Speed** and **Scalability**.\")"
      ],
      "metadata": {
        "id": "EDNgQsE1xNCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f2f691-363c-41cb-b5d0-ae5f22958bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file 'Motor_Vehicle_Collisions_Crashes.csv' was not found. Cannot proceed with timing.\n",
            "\n",
            "--- Running Module 1: Schema and Rule Checks (Pure Pandas) ---\n",
            "\n",
            "Validation Report (Issues Identified and Explained):\n",
            "- **Rule_Violation_Geospatial:** 2163 LAT or 2163 LON values outside NYC bounds.\n",
            "Module 1 completed.\n",
            "\n",
            "--- Running Module 2: Anomaly Detection Checks (Isolation Forest) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1600270818.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anomaly_data['LATITUDE'].fillna(40.73, inplace=True)\n",
            "/tmp/ipython-input-1600270818.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  anomaly_data['LONGITUDE'].fillna(-73.93, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 28,739 potential anomalies using Isolation Forest.\n",
            "\n",
            "Top 5 Records Flagged as Anomalies (Requires Human Review):\n",
            "    COLLISION_ID CRASH DATE  LATITUDE  LONGITUDE  TOTAL_CASUALTIES\n",
            "13       4486660 2021-12-14  40.86816  -73.83148                 4\n",
            "20       4486635 2021-12-14  40.66684  -73.78941                 4\n",
            "22       4486991 2021-12-14  40.65068  -73.95881                 8\n",
            "23       4486284 2021-12-14       NaN        NaN                 6\n",
            "30       4487001 2021-12-13  40.63165  -74.08762                 2\n",
            "Module 2 completed.\n",
            "\n",
            "--- Running Module 3: Schema Enforcement (Structure Check) ---\n",
            "Schema Validation Report (Issues Identified):\n",
            "- **No Schema Violations Detected.**\n",
            "Module 3 completed.\n",
            "\n",
            "--- FINAL METRIC: SCALABILITY AND SPEED ---\n",
            "Total Records Processed: 205,659\n",
            "Total Framework Execution Time: **2.08 seconds**\n",
            "This metric demonstrates the framework's **Speed** and **Scalability**.\n"
          ]
        }
      ]
    }
  ]
}